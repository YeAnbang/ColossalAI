{
    "plugin": "gemini",
    "grad_clip": 1.0,
    "weight_decay": 0.1,
    "warmup_steps": null,
    "tp": 1,
    "zero": 1,
    "pretrain": null,
    "dataset": [],
    "checkpoint_path": null,
    "save_path": "output",
    "max_epochs": 3,
    "batch_size": 4,
    "max_len": 512,
    "mixed_precision": "fp16",
    "lora_rank": 0,
    "lora_train_bias": "none",
    "save_interval": 1000,
    "merge_lora_weights": true,
    "lr": 5e-06,
    "config_file": "config_file",
    "accumulation_steps": 8,
    "log_dir": "logs",
    "use_wandb": false,
    "grad_checkpoint": false,
    "use_flash_attn": false
}
