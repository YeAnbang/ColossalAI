name: Run ChatGPT examples

on:
  pull_request:
    types: [synchronize, opened, reopened]
    paths:
      - "applications/Chat/coati/**"
      - "applications/Chat/requirements.txt"
      - "applications/Chat/setup.py"
      - "applications/Chat/examples/**"

jobs:
  tests:
    name: Run ChatGPT examples
    if: |
      github.event.pull_request.draft == false &&
      github.base_ref == 'main' &&
      github.event.pull_request.base.repo.full_name == 'hpcaitech/ColossalAI'
    runs-on: [self-hosted, 8-gpu]
    container:
      image: hpcaitech/pytorch-cuda:2.1.0-12.1.0
      options: --gpus all --rm -v /data/scratch/colossal-llama2:/data/scratch/colossal-llama2 --shm-size=10.24gb
    timeout-minutes: 60
    defaults:
      run:
        shell: bash
    steps:
      - name: Checkout ColossalAI
        uses: actions/checkout@v2

      - name: Install ChatGPT
        run: |
          cd applications/ColossalChat
          pip install -v .
          pip install -r examples/requirements.txt

      - name: Install Transformers
        run: |
          pip install transformers==4.34.1

      - name: Execute Examples
        run: |
          cd applications/ColossalChat
          rm -rf ~/.cache/colossalai
          ./tests/test_data_preparation.sh
          ./tests/test_train.sh
        env:
          NCCL_SHM_DISABLE: 1
          MAX_JOBS: 8
          PRETRAINED_MODEL_PATH: /home/yeanbang/ci_data/coati_v2/models
          SFT_DATASET: /home/yeanbang/ci_data/coati_v2/sft_data
          PROMPT_DATASET: /home/yeanbang/ci_data/coati_v2/prompt_data
          PREFERENCE_DATASET: /home/yeanbang/ci_data/coati_v2/preference_data
